import numpy as np
from typing import List, Dict, Any, Optional, Tuple
from sklearn.metrics.pairwise import cosine_similarity
from sentence_transformers import SentenceTransformer
from pydantic import BaseModel, Field
from wikidata import wikidata_search

class Property(BaseModel):
    key: str
    value: str

class Node(BaseModel):
    id: str = Field(..., description="The identifying property of the node in Title Case")
    type: str = Field(..., description="The entity type / label of the node in PascalCase.")
    properties: Optional[List[Property]] = Field(default=[], description="Detailed properties of the node")
    aliases: List[str] = Field(default=[], description="Alternative names or identifiers for the entity in Title Case")
    definition: Optional[str] = Field(None, description="A concise definition or description of the entity")

# Correct model name
model = SentenceTransformer('all-MiniLM-L6-v2', tokenizer_kwargs={"clean_up_tokenization_spaces": False})

def convert_case(text: str) -> str:
    return text.title().replace(" ", "")

def calculate_cosine_similarity(sentences: List[str]) -> np.ndarray:
    sentence_embeddings = model.encode(sentences)
    return cosine_similarity([sentence_embeddings[0]], sentence_embeddings[1:]).flatten()

def link_nodes(entities: List[Node], sim_thresh: float = 0.5) -> Tuple[List[Dict[str, Any]], List[Node]]:
    matched_nodes, unmatched_nodes = [], []

    for entity in entities:
        res = wikidata_search(entity.id)
        if not res:
            unmatched_nodes.append(entity)
            continue

        if ' ' not in entity.id:
            tcase_id = convert_case(entity.id)
            eid = f"{entity.id}/{tcase_id}" if tcase_id != entity.id else entity.id
        else:
            eid = f"{entity.id.replace(' ', '')}/{entity.id}"

        sentences = [f"{eid}, {', '.join(entity.aliases)}, {convert_case(entity.type)}, {entity.definition}"]
        sentences.extend([f"{r['label']}, {', '.join(r['aliases'])}, {r['type']}, {r['description']}".lower() for r in res])
        
        scores = calculate_cosine_similarity(sentences)
        best_match_index = np.argmax(scores)

        if scores[best_match_index] < sim_thresh:
            unmatched_nodes.append(entity)
        else:
            best_match = res[best_match_index]
            matched_nodes.append({
                "id": best_match["id"],
                "definition": entity.definition,
                "desc": best_match["description"],
                "type": entity.type,
                "wiki_type": best_match["type"],
                "alias": entity.id,
                "url": best_match["url"].strip('/'),
                "labels": entity.aliases + best_match['aliases'] + [best_match['label']],
                "properties": {p.key: p.value for p in entity.properties}
            })

    return matched_nodes, unmatched_nodes

# Example usage
if __name__ == "__main__":  
    nodes = [
        Node(id="tokamak", type="Concept", aliases=["tokamak"], definition="A device for magnetic confinement of plasma by a combination of a toroidal magnetic field and a current flowing through the plasma in which conditions for thermonuclear fusion ignition can be achieved. The word “tokamak” is of Russian origin and is an acronym for “TOroidalnaya KAmera i MAgnitnye Katushki” — toroidal chamber and magnetic coils. The magnetic field necessary to keep the hot plasma inside the toroidal chamber is generated as a combination of the field of the toroidal coils and the magnetic field generated by the current flowing through the plasma. Since the current in the plasma is induced on the transformer principle, the tokamak is a pulse device.")
    ]
    matched, unmatched = link_nodes(nodes)
    print("Matched Nodes:", matched)
    print("Unmatched Nodes:", unmatched)

